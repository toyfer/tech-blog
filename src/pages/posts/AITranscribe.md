---
layout: ../../layouts/Post.astro
title: OpenAIのWhisperとElectronで文字起こしソフトを作成しました
---

# はじめに
OpenAIのWhisperを活用した文字起こしソフトをElectronで作成したのでご紹介します。

# 主な機能と用途
できること

* 音声ファイルを読み込み、文字起こしをしてCSVを出力する
* 出力したCSVと元の音声ファイルを使用して、時系列のテキスト毎に音声を再生することができる

用途としては
* 会議録作成の省力化
* 一字一句に文字起こしする場合の発言確認

などに利用する想定です。

## 文字起こし機能
以下が文字起こし機能の画面です。  

![](https://storage.googleapis.com/zenn-user-upload/b1a87c8ea2eb-20240115.png )

上から精度選択、コンソール出力、ファイル選択欄、ファイル選択ボタン、スタートボタンのシンプルな構成からなっています。

精度と音声ファイルを選択して、スタートを押下すると処理が始まります。

![](https://storage.googleapis.com/zenn-user-upload/2229d4b84140-20240115.png)

完了すると次のように、終了していることを教えてくれます。

![](https://storage.googleapis.com/zenn-user-upload/fffb3a7d4b0f-20240115.png)

## 文字起こしサポーター機能
文字起こし画面下部の文字起こしサポーターを起動ボタンを押下すると、文字起こしサポーターが起動します。

この画面では、出力されたCSVと元の音声を用いて、指定のテキストの時間から音声を再生したり、内容を確認したりすることができます。

![](https://storage.googleapis.com/zenn-user-upload/268a4975099c-20240115.png)

また、Chromium実装のAudioPlayerで再生速度を調整することも可能です。

# 主な技術構成
| 項目 | 内容 |
| --- | --- |
| GUIフレームワーク | Electron 20.6 + Bootstrap5 |
| 音声入力変換 | FFmpeg |
| 文字起こしロジック | FasterWhisper |
| FasterWhisper実行 | Embeddable Python 3.11.4 |

## 文字起こし処理の流れ
1. ElectronでGUI表示
2. ファイル選択時にElectronがメインプロセスでファイルパスを取得
3. スタート押下時に、精度の選択に応じて、レンダラプロセスがメインプロセスにコマンドライン引数（音声ファイルパス、使用されるモデル）を渡す
4. メインプロセスが引数をもとに子プロセスとしてFFmpegを呼び出し、一般的な非可逆圧縮（mp3、m4a）からWAV音声ファイルをTempフォルダに生成する
5. FFmpeg実行終了後、必要な引数をPythonへ渡し、PtyhonからFasterWhisperを呼び出して文字起こしを行いながら、Pythonの中で結果をCSVを出力する。
6. Pythonの終了コード発行により、メインプロセスでの処理が終了することで一連の作業が完了します。 

## 作成に当たって
OpenAIのWhisperが出た当時、これは使えたら業務改善できるなと思い、個人で利用を進めていました。
最初は自分だけ使用できればよかったためPythonのみを使用しbatファイルを作成して、CSVを出力する機能だけ持っていました。

ただ、最近ではDXが大きく取り上げられていることもあり、会社でも議事録作成の省力化などに向けて検討が進んでいましたが、コストが嵩むことから積極的ではなかったため、「お試しできますよ」と提案したのが始まりです。

最初はGUIが容易に実装できるだろうと考えC#で作成していましたが、社内で実証的に使用したいとの声があり、個人開発ではなく、業務時間を用いて開発ができることとなったため、VisualStudioCommunity版では、ライセンス上開発を行えなくなり（当時はプライベートリポジトリで作成していました）、別のGUI実装を検討することとしました。

## 言語&フレームワーク選定
当時は次の中で選択肢を考えていました。
* Dart（Flutter）
* Python（Tkinter）
* Javascript + Node.js（Electron）
Pythonはすでにライブラリで使用するので面白くないなと思い除外
Flutterに手を付けます。

## Flutterでの開発
最初はUIもGoogleらしくマテリアルデザインが特徴的で、Dart言語も特に問題には感じていませんでした。
が、どちらかというとモバイル向けのUI色が強めで、Dartの仕様をゼロから学ぶのは高コストで開発時間が大きくかかると判断し、途中で断念しました。

## Electronでの開発
ElectronではバックエンドがNode.js、JavaScriptで、当時ポータルサイト更改を終えた時期だったこともあり、ある程度理解があったため、Node.jsの仕様とElectronの仕様さえ分かればGUIはHTMLベースでBootstrapを使用して楽に記述できるだろうと考えていました。

## IPCの壁
GUI上からメインプロセス内でFFmpegとWhisperの実行が行えればと考えていましたが、ElectronにはIPC（プロセス間通信）があります。
Electronでは、セキュリティ上の理由から、ローカルのリソースにアクセスできるメインプロセスと画面の動作等を管理するレンダラプロセスは分離されます。エントリポイントとしてPreloadが仲介し、それぞれにアクセスするためのAPIをあらかじめ用意していることが必要です。

### 実行結果を待っている間にGUIが更新できない
利用する側の目線からすれば、0.7倍～等倍程度（PCスペックによる）で文字起こしが実行されるので、長時間会議などの文字起こしではいつ完了するかわかりません。そのため、コンソールなどを更新し、利用者へ進捗を通知する必要があります。

Electron公式ドキュメントを読んで、「適宜出力される結果を待てればいいのだから、`ipcMain.handle`でメインプロセスの実行、戻り値をコンソールへ出力すればよいのでは」と考え安易に実装しました。

しかし、戻り値が渡されるは文字起こしプロセスが終了する時となるため、文字起こしが終わってから内容が返されることになってしまい進捗が通知できませんでした。（しばらく気づきませんでした）

最終的には、`ipcRenderer.send`と`ipcMain.on`を実装し、それぞれにメインプロセス内関数の実行、出力の戻り値をリスナーで受けてコンソールに出力する仕組みにしました。

また、レンダラプロセスで音声時間に基づいて概ねの予測をプログレスバーで表示するようにしました。

### コンソール出力の文字化け
会社で使用しているPCはWindowsであるため、シェルは基本的にShiftJISが利用されます。対して、HTMLはUTF-8、Pythonは内部がUTF-8、標準出力がShiftJIS、Node.jsはUTF-8です。複数の仕組みを利用している関係上、コンソールへの出力が正しく受け取れない状態になってしまいました。

対応として、Node.jsから呼び出すシェルに`chcp 65001`を付与し、全体の出力をUTF-8に統一してから実行、出力を行うようにしています。

## 役所のネットワーク制約
役所によっては、通常業務で利用する端末はインターネットに接続されておらず、自身の職場もインターネットは利用できません。また、ランタイムのインストールも敷居が高いため、GithubActionsを活用し、Electronアプリケーションのビルド、PythonはEmbeddable版を利用し、FFmpegとFasterWhisperもビルド時にすべて取得したうえでディレクトリごとビルドを実行するようにしています。
また、開発もnpmなどが利用できないため、VSCode.devを利用してWEB上で開発を行いました。

# 感想
とりあえず形になってよかったなと思うところが大きいのと、Node.jsの処理やVSCodeなどで実際に利用されているElectronに触れたのはデスクトップアプリケーション開発の選択肢としてとても大きな経験になりました。

また、最近では趣味のコミュニティでマインクラフトのプラグイン開発を行っていますが、JavaやKotlinを触ることも多く、コンパイラ段階で止められることの有用性を実感しているため、TypeScriptなどにも触ってみたいなと思ってます。